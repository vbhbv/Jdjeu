# scraper.py (Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…Ø­ØµÙ†)
import logging
import re
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin, quote, urlparse # Ø§Ø³ØªÙŠØ±Ø§Ø¯ urlparse
from config import MAX_SEARCH_RESULTS, NOOR_BOOK_BASE_URL

logging.basicConfig(level=logging.INFO)

class LibraryScraper:
    
    def __init__(self):
        # Ù„Ù… Ù†Ø¹Ø¯ Ù†Ø­Ø¯Ø¯ Referer Ù‡Ù†Ø§ Ø¨Ù„ Ù†Ø­Ø¯Ø¯Ù‡ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ§Ù‹
        self.base_headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept-Language': 'ar-EG,ar;q=0.9,en-US;q=0.8,en;q=0.7'
        }

    # ... (Ø¯Ø§Ù„Ø© search_library ØªØ¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡ÙŠ)
    # ...

    def get_download_info(self, book_url):
        """
        Ø§Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„Ù…Ø­ØµÙ†: ØªÙØ§ÙˆØ¶ Ø¢Ù„ÙŠØŒ ØªØ­Ø¯ÙŠØ« Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ù„Ø±Ø£Ø³ RefererØŒ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø®Ø·Ø§Ø¡ Ø£ÙØ¶Ù„.
        """
        logging.info(f"Attempting Automated Negotiation for download link: {book_url}")
        
        # ğŸ’¡ Ø§Ù„Ù†Ù‚Ø¯ 4: ØªØ­Ø¯ÙŠØ« Ø±Ø£Ø³ Referer Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ§Ù‹
        # Ù†Ø³ØªØ®Ø¯Ù… book_url ÙƒÙ…Ø±Ø¬Ø¹ Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù…Ù† Ù†ÙØ³ Ø§Ù„Ù†Ø·Ø§Ù‚
        referer_domain = urlparse(book_url).scheme + "://" + urlparse(book_url).netloc
        
        current_headers = self.base_headers.copy()
        current_headers['Referer'] = referer_domain
        
        try:
            # 1. Ø¬Ù„Ø¨ ØµÙØ­Ø© Ø§Ù„ÙƒØªØ§Ø¨ (Ø§Ù„Ù†Ù‚Ø¯ 5: Ù…Ø±ÙˆÙ†Ø© Ø£ÙØ¶Ù„)
            response = requests.get(book_url, headers=current_headers, timeout=15, allow_redirects=True)
            
            # ğŸ’¡ Ø§Ù„Ù†Ù‚Ø¯ 5: Ù„Ø§ Ù†Ø³ØªØ®Ø¯Ù… raise_for_status() Ø¨Ø´ÙƒÙ„ ØµØ§Ø±Ù… ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
            if response.status_code >= 400:
                logging.warning(f"Initial book page request failed with status: {response.status_code}")
                return None, "error"
                
            soup = BeautifulSoup(response.content, 'lxml')
            
            # 2. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ø²Ø±Ø§Ø± Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ø§Ù‹
            download_button = soup.select_one('a[href*="/download/"], a.btn-download, a[download], button')
            
            if download_button:
                download_link_partial = download_button.get('href') or download_button.get('data-href')

                if download_link_partial:
                    full_download_link = urljoin(response.url, download_link_partial)

                    # 3. Ø§Ù„ØªÙØ§ÙˆØ¶ Ø§Ù„Ø¢Ù„ÙŠ: Ø·Ù„Ø¨ Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
                    # ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† full_download_link Ù‡Ùˆ Ø§Ù„Ø¢Ù† Ø§Ù„Ù…Ø±Ø¬Ø¹ (Referer) Ù„Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªØ§Ù„ÙŠØ©
                    negotiation_headers = self.base_headers.copy()
                    negotiation_headers['Referer'] = response.url # ØµÙØ­Ø© Ø§Ù„ÙƒØªØ§Ø¨ Ù‡ÙŠ Ø§Ù„Ù…Ø±Ø¬Ø¹

                    final_file_response = requests.get(
                        full_download_link, 
                        headers=negotiation_headers, # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø±Ø¤ÙˆØ³ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
                        timeout=30, 
                        allow_redirects=True
                    )
                    
                    final_url = final_file_response.url 
                    
                    # 4. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ (Ø§Ù„Ù†Ù‚Ø¯ 2: ØªØ¬Ø§Ù‡Ù„ ØµÙØ­Ø© Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±)
                    # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ù…Ù„ÙØŒ Ø£Ùˆ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¨Ø· ÙŠÙ†ØªÙ‡ÙŠ Ø¨Ù€ .php Ø£Ùˆ .html
                    if final_url.lower().endswith(('.pdf', '.epub')):
                        file_ext = '.pdf' if final_url.lower().endswith('.pdf') else '.epub'
                        logging.info(f"Success! Found direct file link: {final_url}")
                        return final_url, file_ext
                    
                    # ğŸ’¡ Ø§Ù„Ù†Ù‚Ø¯ 2: ÙØ´Ù„ Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
                    logging.warning(f"Final URL is not a file: {final_url}")
            
            # ğŸ’¡ Ø§Ù„Ù†Ù‚Ø¯ 1: Ù„Ù… Ù†Ø¬Ø¯ Ø²Ø± ØªØ­Ù…ÙŠÙ„ ÙˆØ¸ÙŠÙÙŠ (Ø¨Ø³Ø¨Ø¨ JavaScript)
            logging.warning("Failed to find a functional download link (JS dependency likely).")
            return None, "link"
            
        except Exception as e:
            logging.error(f"Critical error during Automated Negotiation: {e}")
            return None, "error"
