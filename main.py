# main.py
import logging
import os
import requests
import time
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ApplicationBuilder, CommandHandler, ContextTypes, MessageHandler, filters, CallbackQueryHandler

from config import TELEGRAM_BOT_TOKEN
from scraper import LibraryScraper

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', 
    level=logging.INFO
)

scraper = LibraryScraper()

# 1. Ø£Ù…Ø± /start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "ğŸ‘‹ Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ø¨ÙˆØª Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©! Ø£Ø±Ø³Ù„ Ù„ÙŠ Ø§Ø³Ù… Ø§Ù„ÙƒØªØ§Ø¨ Ù„Ù„Ø¨Ø­Ø« ÙˆØ§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ø§Ù„Ø¢Ù…Ù†."
    )

# 2. Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø¨Ø­Ø«
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.message.text
    await update.message.reply_text(f"ğŸ” Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†: `{query}`...", parse_mode='Markdown')
    
    try:
        results = scraper.search_library(query)
        
        if not results:
            await update.message.reply_text(
                f"Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ù„Ù€ `{query}`. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ø³Ù… Ø§Ù„ÙƒØªØ§Ø¨ Ø£Ùˆ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨ÙƒÙ„Ù…Ø§Øª Ù…Ø®ØªÙ„ÙØ©.", 
                parse_mode='Markdown'
            )
            return

        book_list_text = f"ğŸ“š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« ({len(results)} Ù†ØªØ§Ø¦Ø¬):\n"
        keyboard = []
        
        for i, book in enumerate(results):
            book_list_text += f"\n**{i + 1}. {book['title']}**"
            book_id_callback = f"download_{book['url']}" 
            keyboard.append([InlineKeyboardButton(f"â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ {i + 1}", callback_data=book_id_callback)])
            
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        await update.message.reply_text(
            book_list_text, 
            reply_markup=reply_markup, 
            parse_mode='Markdown'
        )

    except Exception as e:
        logging.error(f"Search operation failed: {e}")
        await update.message.reply_text("âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø¨Ø­Ø«.")

# 3. Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø·Ù„Ø¨ Ø§Ù„ØªØ­Ù…ÙŠÙ„ ÙˆØ§Ù„Ø­Ø°Ù Ø§Ù„ÙÙˆØ±ÙŠ
async def handle_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Ø§Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„ÙƒØ§Ù…Ù„: Ø¬Ù„Ø¨ Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ø¨Ø§Ø´Ø± -> ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù -> Ø¥Ø±Ø³Ø§Ù„Ù‡ -> Ø­Ø°ÙÙ‡ ÙÙˆØ±Ø§Ù‹."""
    query_callback = update.callback_query
    data = query_callback.data
    
    if data.startswith("download_"):
        book_url = data.replace("download_", "", 1)
        
        await query_callback.answer("Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ù„Ø§Øµ Ø±Ø§Ø¨Ø· Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±...")
        
        # 1. Ø¬Ù„Ø¨ Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¨Ø§Ø´Ø± (Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„Ù…Ø¨ØªÙƒØ±)
        download_link, file_ext = scraper.get_download_info(book_url)
        
        if not download_link or file_ext not in ['.pdf', '.epub']:
            await query_callback.message.reply_text("Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø±Ø§Ø¨Ø· Ù…Ù„Ù Ù…Ø¨Ø§Ø´Ø± (PDF/EPUB) Ù„Ù‡Ø°Ø§ Ø§Ù„ÙƒØªØ§Ø¨.")
            return

        await query_callback.message.reply_text("â³ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù (PDF/EPUB) Ù…Ø¤Ù‚ØªØ§Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ±ÙØ±ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±...")
        
        temp_file_name = f"temp_book_{os.path.basename(book_url).split('?')[0]}_{time.time()}{file_ext}"
        
        try:
            # 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ù…ÙƒØªØ´Ù
            file_response = requests.get(download_link, stream=True, timeout=90) # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù…Ù‡Ù„Ø©
            file_response.raise_for_status()
            
            with open(temp_file_name, 'wb') as temp_file:
                for chunk in file_response.iter_content(chunk_size=8192):
                    temp_file.write(chunk)
            
            # 3. Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù„Ù Ø¥Ù„Ù‰ ØªÙ„ÙŠØ¬Ø±Ø§Ù… ÙƒÙˆØ«ÙŠÙ‚Ø©
            with open(temp_file_name, 'rb') as doc_file:
                await query_callback.message.reply_document(
                    document=doc_file,
                    caption="âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒØªØ§Ø¨ Ø¨Ù†Ø¬Ø§Ø­. (ØªÙ… **Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù ÙÙˆØ±Ø§Ù‹** Ù…Ù† Ø§Ù„Ø³ÙŠØ±ÙØ± Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø°Ø§ÙƒØ±Ø©)",
                    parse_mode='Markdown'
                )

            # 4. Ø§Ù„Ø­Ø°Ù Ø§Ù„ÙÙˆØ±ÙŠ
            os.remove(temp_file_name)
            logging.info(f"File {temp_file_name} successfully sent and deleted.")
            await query_callback.answer("ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù„Ù ÙˆØ­Ø°ÙÙ‡ Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø©.")
            
        except Exception as e:
            logging.error(f"Error during file download/send: {e}")
            await query_callback.message.reply_text("âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù. Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù ÙƒØ¨ÙŠØ±Ø§Ù‹ Ø¬Ø¯Ø§Ù‹.")
        finally:
            # ØªÙ†Ø¸ÙŠÙ Ø£ÙŠ Ù…Ù„ÙØ§Øª Ù…ØªØ¨Ù‚ÙŠØ© ÙÙŠ Ø­Ø§Ù„Ø© ÙˆØ¬ÙˆØ¯ Ø®Ø·Ø£
            if os.path.exists(temp_file_name):
                os.remove(temp_file_name)
                logging.info(f"Cleaned up residual file: {temp_file_name}")

# 4. Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
def main():
    """ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨ÙˆØª."""
    application = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).build()

    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.TEXT & (~filters.COMMAND), handle_message))
    application.add_handler(CallbackQueryHandler(handle_callback))
    
    print("Bot is running...")
    application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == '__main__':
    main()
